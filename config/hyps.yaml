model:
  model_name: 't5-small'
  dropout: 0.3
  expansion_factor: 4
  num_layers: 6
  num_heads: 8
  feedback_mode: True # TODO for self feed into decoder (annoying to implement)
  note_loss_weight: 0.5
  duration_loss_weight: 0.25
  gap_loss_weight: 0.25

training:
  batch_size: 32
  epochs: 10
  lr: 5e-5
  weight_decay: 0
  train_encoder: False

data:
  data_dir: './data/new_dataset'
  max_sequence_length: 20
  output_eos: 1
  use_syllables: False
  note_vocab_size: 128
  duration_vocab_size: 32
  gap_vocab_size: 32

seed: 42